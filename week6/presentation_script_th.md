# การนำเสนอสัปดาห์ที่ 6: การจำแนกฟันผุแบบระบุพื้นผิว (Surface-Aware Dental Caries Classification)

> **คู่มือผู้นำเสนอ** — 5 สไลด์, ประมาณ 15 นาที  
> ภาพ Hero shots: `week6/presentation_hero_shots/`

---

## สไลด์ที่ 1: ปัญหา — ความท้าทายของภาพ 2 มิติ

### หัวข้อสำคัญ
- ภาพรังสีรอบปลายราก (Periapical X-ray) คือ **ภาพเงา 2 มิติ** ของกายวิภาค 3 มิติ
- โมเดลตรวจจับทั่วไปให้ผลลัพธ์เป็น **กรอบสี่เหลี่ยม (Bounding Box)** — "มีฟันผุอยู่ตรงนี้"
- แต่กรอบสี่เหลี่ยม **ไม่สามารถบอกทันตแพทย์ได้ว่าพื้นผิวด้านไหน** ที่ถูกทำลาย
- **ด้านประชิด (Mesial)? ด้านไกลกลาง (Distal)? ด้านบดเคี้ยว (Occlusal)?** — พื้นผิวเป็นตัวกำหนดแผนการรักษา
- การบูรณะ Class II (ด้านประชิด) เป็นขั้นตอนที่แตกต่างอย่างสิ้นเชิงจาก Class I (ด้านบดเคี้ยว)

### บทพูด
> "ผมขอเริ่มต้นด้วยข้อจำกัดพื้นฐานที่เราต้องเผชิญ ภาพรังสีรอบปลายรากนั้น โดยแก่นแท้แล้วคือภาพเงาสองมิติของวัตถุสามมิติ เมื่อเรานำโมเดล YOLO มาตรวจจับบนภาพเหล่านี้ สิ่งที่ได้คือกรอบสี่เหลี่ยม — สี่เหลี่ยมที่บอกแค่ว่า *'มีฟันผุอยู่แถวนี้'*
>
> แต่ปัญหาคือ: สี่เหลี่ยมนั้นไม่ได้บอกอะไรเลยว่ารอยผุ **อยู่บนพื้นผิวด้านไหน** ของฟัน ด้าน Mesial หรือเปล่า? ด้าน Distal? ด้าน Occlusal? ความแตกต่างนี้ไม่ใช่เรื่องทางวิชาการเพียงอย่างเดียว — มันกำหนดแผนการรักษาโดยตรง การบูรณะด้าน Mesial-Occlusal ต้องการการเตรียมฟันที่แตกต่างอย่างสิ้นเชิงจากการอุดฟันด้าน Occlusal อย่างเดียว
>
> **ตำแหน่งคือทุกสิ่งในการวินิจฉัย** และนี่คือช่องว่างที่ผมตั้งใจจะปิด"

### สิ่งที่ควรแสดง
- แสดงภาพ X-ray พร้อมกรอบ Bounding Box ของ YOLO รอบฟันที่มีรอยผุ
- ใส่เครื่องหมายคำถาม: **"M? O? D?"**
- ใช้ภาพจาก `evaluation_output/` แสดงมุมมองภาพรวม (ครึ่งบนของ Dashboard)

---

## สไลด์ที่ 2: แนวทางแก้ปัญหา — PCA + Multi-Zone Point-Cloud Voting

### หัวข้อสำคัญ
- **ขั้นตอนที่ 1 — PCA Orientation Normalization**
  - คำนวณ Eigenvectors ของรูปหลายเหลี่ยมจากการแบ่งส่วนฟัน (Segmentation Polygon)
  - Principal Component ที่ 1 = "แกนยาว" ของฟัน
  - หมุนพิกัดทั้งหมดเข้าสู่กรอบมาตรฐาน → ฟันทุกซี่ชี้ไปทิศทางเดียวกัน
- **ขั้นตอนที่ 2 — การแบ่งโซน M-C-D**
  - แบ่ง Bounding Box ที่ผ่าน PCA แล้วออกเป็น 3 โซนเท่ากัน: Mesial | Central | Distal
  - การพลิกตาม Quadrant: FDI Q1/Q4 (ด้านขวา) vs Q2/Q3 (ด้านซ้าย) กำหนดว่าด้านไหนคือ Mesial
- **ขั้นตอนที่ 3 — 5% Point-Cloud Voting** (แทนที่การใช้จุดศูนย์กลางจุดเดียว)
  - ฉายพิกเซลรอยผุ **ทุกจุด** เข้าสู่ระบบพิกัดที่หมุนแล้ว
  - นับสัดส่วนของจุดในแต่ละโซน (M, C, D)
  - **โซนใดที่ ≥ 5%** จะถูกรายงาน — ตามมาตรฐาน G.V. Black "Any Involvement"
  - กำจัดสัญญาณรบกวนด้วย Connected-Component (กลุ่มที่ < 15 พิกเซลจะถูกตัดออก)
- **ผลลัพธ์**: `MOD`, `MO`, `DO`, `M`, `D`, `O` — ป้ายกำกับที่นำไปใช้ทางคลินิกได้จริง

### บทพูด
> "แล้วเราจะไปจากกรอบสี่เหลี่ยมไปสู่การวินิจฉัยระบุพื้นผิวได้อย่างไร? สามขั้นตอนครับ
>
> **อย่างแรก PCA** ฟันแต่ละซี่ใน X-ray อยู่ในมุมที่ต่างกัน — บางซี่เอียง บางซี่หมุน ผมใช้ Principal Component Analysis กับรูปหลายเหลี่ยมของการแบ่งส่วนฟันแต่ละซี่เพื่อหา Eigenvectors — ซึ่งก็คือแกนยาวตามธรรมชาติของฟัน จากนั้นผมหมุนทุกอย่างเข้าสู่กรอบมาตรฐาน ตอนนี้ฟันทุกซี่ 'ชี้' ไปทิศทางเดียวกันหมด ไม่ว่าจะอยู่ในมุมไหนของภาพเดิม
>
> **อย่างที่สอง การแบ่งโซน** เมื่อฟันถูกจัดแนวแล้ว ผมแบ่ง Bounding Box ที่หมุนด้วย PCA แล้วออกเป็นสามโซนเท่ากัน: Mesial, Central, และ Distal — โซน M-C-D สิ่งสำคัญคือ ด้านไหนเป็น 'Mesial' ขึ้นอยู่กับ FDI Quadrant สำหรับฟันด้านขวาของผู้ป่วย ซึ่งคือ Quadrant 1 และ 4 — Mesial จะอยู่ทางซ้ายในกรอบที่หมุนแล้ว สำหรับด้านซ้ายก็จะพลิกกลับ ตรรกะการพลิกตาม Quadrant นี้แหละคือหนึ่งในการแก้ไขสำคัญที่ทำให้ Surface Accuracy ของเราพุ่งจาก 27% ไปเป็น 87%
>
> **อย่างที่สาม — และนี่คือจุดเปลี่ยนที่แท้จริง — Point-Cloud Voting** วิธีเดิมใช้จุดศูนย์กลางจุดเดียว: หนึ่งจุด หนึ่งโซน หนึ่งป้ายกำกับ ซึ่งล้มเหลวอย่างสิ้นเชิงกับรอยผุขนาดใหญ่ที่ครอบคลุมหลายพื้นผิว ผมจึงเปลี่ยนมาฉายพิกเซลรอยผุ *ทุกจุด* เข้าสู่พื้นที่ที่หมุนแล้ว แล้วนับว่ามีกี่จุดตกในแต่ละโซน ถ้า 5% ขึ้นไปของจุดสัมผัสโซนใด โซนนั้นจะถูกรายงาน เกณฑ์ 5% นี้เป็นไปตามมาตรฐานการจำแนกของ G.V. Black — *การเกี่ยวข้องใดๆ* ของพื้นผิวถือว่านับ นอกจากนี้ผมยังใช้ Connected-Component Filtering เพื่อกำจัดสัญญาณรบกวน — กลุ่มที่เล็กกว่า 15 พิกเซลจะถูกตัดออกก่อนการโหวต
>
> ผลลัพธ์ที่ได้คือป้ายกำกับที่มีความหมายทางคลินิก: M, D, O, MO, DO, หรือ MOD"

### สิ่งที่ควรแสดง
- แสดง **ครึ่งล่าง** ของภาพ Dashboard (แผง PCA) จากเคส Complex Win
- แนะนำ: **เคส MOD** เช่น `2_The_Complex_Win/case_57_MOD_...png` หรือ `case_365_MOD_...png`
- ชี้ให้เห็น: แกน PCA สีน้ำเงิน เส้นแบ่งโซนสีแดง จุดรอยผุสี Cyan/เหลือง/ม่วงแดง ในโซน M/C/D

---

## สไลด์ที่ 3: หลักฐาน — Hero Shots

### หัวข้อสำคัญ
- **The Perfect Match** — TP ถูกต้องทั้งพื้นผิว มี IoU สูง
  - โมเดลและ Ground Truth เห็นตรงกันอย่างสมบูรณ์
  - สร้าง **ความเชื่อมั่นเบื้องต้น** ในระบบ
- **The Complex Win** — TP แบบหลายพื้นผิว (MO / DO / MOD)
  - ตรรกะจุดศูนย์กลางแบบเดิม → จะให้ป้ายกำกับเป็น "O" (ตรงกลางเท่านั้น)
  - Point-Cloud Voting แบบใหม่ → ระบุ **การขยายเข้าไปในโซน M หรือ D** ได้อย่างถูกต้อง
  - ตรวจพบเคสหลายพื้นผิว 328 เคส จากผู้ป่วย 500 ราย
- **ทำไมจึงสำคัญ**: ฟันผุหลายพื้นผิวเปลี่ยน Class ของการบูรณะ
  - Class I (O เท่านั้น) → Class II (MO/DO/MOD) = การเตรียมฟันที่ invasive มากขึ้น

### บทพูด
> "ผมขอแสดงหลักฐานให้ดูครับ
>
> อย่างแรก Perfect Match *[แสดงภาพ]* ที่นี่โมเดลตรวจพบรอยผุ ระบุฟันถูกซี่ และ — ที่สำคัญที่สุด — ระบุพื้นผิวได้ถูกต้อง Ground Truth บอกว่า Distal-Occlusal; โมเดลก็บอกว่า Distal-Occlusal IoU กับรูปหลายเหลี่ยมของฟันอยู่ที่ 0.26 และป้ายกำกับพื้นผิวตรงกันอย่างสมบูรณ์ นี่คือตัวสร้างความเชื่อมั่นของเรา
>
> แต่เรื่องจริงอยู่ตรงนี้ — Complex Wins *[แสดงเคส MOD]* ดูเคสนี้ครับ รอยผุขยายจาก Mesial Marginal Ridge ข้ามพื้นผิว Occlusal ไปจนถึง Distal ถ้าผมใช้วิธีจุดศูนย์กลางแบบเดิม — ซึ่งหย่อนจุดเดียวลงที่จุดศูนย์กลางมวล — มันจะตกตรงกลางโซน Central พอดีและรายงานว่า 'Occlusal' ซึ่งไม่ผิดทีเดียว แต่เป็นอันตรายเพราะไม่สมบูรณ์ มันพลาดการขยายเข้าไปทาง Proximal ทั้งหมด
>
> ด้วย Point-Cloud Voting ระบบฉายพิกเซลรอยผุทั้งหมดเข้าสู่พื้นที่ที่จัดแนวด้วย PCA จะเห็นจุดสี Cyan ในโซน Mesial สีเหลืองใน Central และสีม่วงแดงใน Distal สัดส่วนออกมาประมาณ M=22%, C=45%, D=33% — ทั้งหมดสูงกว่าเกณฑ์ 5% ของเรา ระบบจึงรายงานว่า **MOD** ได้อย่างถูกต้อง
>
> สิ่งนี้สำคัญทางคลินิก: รอยผุเฉพาะ Occlusal เป็นการบูรณะ Class I แต่รอยผุ MOD เป็น Class II — การเตรียมฟันที่ invasive กว่ามาก การแยกแยะนี้ถูกต้องมีผลกระทบโดยตรงต่อการวางแผนการรักษา
>
> จากทั้ง 500 เคส โมเดลระบุเคสที่มีฟันผุหลายพื้นผิวได้ **328 เคส** — แบ่งเป็น MOD 151 เคส, MO 131 เคส, และ DO 46 เคส"

### สิ่งที่ควรแสดง
- **ด้านซ้าย**: Dashboard จาก Perfect Match ใน `1_The_Perfect_Match/` (เช่น `case_217_DO_iou0.26.png`)
- **ด้านขวา**: เคส MOD จาก Complex Win ใน `2_The_Complex_Win/` (เช่น `case_57_MOD_...png`)
- ซูมเข้าไปที่แผง PCA เพื่อแสดงการกระจายรอยผุสามสีในแต่ละโซน
- เสริม: แสดงเปรียบเทียบ "จุดศูนย์กลางจะบอกว่า O" vs "Voting บอกว่า MOD"

---

## สไลด์ที่ 4: ผลการดำเนินงาน

### หัวข้อสำคัญ
- **ประสิทธิภาพการตรวจจับ** (500 เคส, 2,272 annotations)
  - True Positives: 1,821
  - False Positives: 293
  - False Negatives: 158
  - **Precision: 0.86** — เมื่อโมเดลระบุว่ามีฟันผุ จะถูกต้อง 86%
  - **Recall: 0.92** — โมเดลจับฟันผุได้ 92% ของทั้งหมด
  - **F1-Score: 0.89** — สมดุลที่ดีระหว่าง Precision และ Recall
- **Surface Classification Accuracy: 87.31%**
  - พื้นฐานสัปดาห์ที่ 5 (จุดศูนย์กลางจุดเดียว): **27%**
  - สัปดาห์ที่ 6 (PCA + Point-Cloud Voting): **87%** — ดีขึ้น 3.2 เท่า
- **ความโปร่งใส**: มี Confusion Matrix เต็มรูปแบบและ CSV รายเคส

### บทพูด
> "มาดูตัวเลขกันครับ
>
> จาก 500 เคส และ Ground-Truth Annotations 2,272 รายการ ระบบทำ F1-Score ได้ **0.89** — โดยมี Precision ที่ 0.86 และ Recall ที่ 0.92 ตัวเลข Recall นี้สำคัญมากในบริบทของการคัดกรอง: เราจับฟันผุได้ 92% ของทั้งหมดในชุดข้อมูล
>
> แต่ตัวชี้วัดหลักของสัปดาห์นี้คือ **Surface Accuracy** ในสัปดาห์ที่ 5 ที่ใช้วิธีจุดศูนย์กลางแบบง่าย Surface Accuracy อยู่ที่แค่ 27% ด้วยการ Normalize ด้วย PCA, การจัดแนวตาม Quadrant, และเกณฑ์ Point-Cloud Voting 5% ตัวเลขนั้นพุ่งขึ้นมาเป็น **87.31%** นั่นคือการปรับปรุง 3.2 เท่า — และเป็นความแตกต่างระหว่างระบบที่บอกได้แค่ว่า 'มีฟันผุ' กับระบบที่บอกได้ว่า 'มีฟันผุ *บนพื้นผิว Mesial-Occlusal*'
>
> เพื่อความโปร่งใสอย่างเต็มที่ ทุกเคสมี CSV ประเมินผลและ Validation Dashboard เป็นของตัวเอง Confusion Matrices ถูกเผยแพร่ควบคู่กับผลลัพธ์ ไม่มีอะไรถูกซ่อนครับ"

### สิ่งที่ควรแสดง
- **ตารางสรุปตัวชี้วัด** (สไลด์แบบเรียบง่าย)
- เสริม: กราฟแท่งแสดงการเปลี่ยนแปลง Surface Accuracy 27% → 87%
- อ้างอิง: `evaluation_output/evaluation_summary.json` สำหรับตัวเลขที่แน่นอน

---

## สไลด์ที่ 5: อภิปราย — "สายตา AI"

### หัวข้อสำคัญ
- **False Positives 293 รายการ** — แต่ไม่ใช่ทุกรายการที่ "ผิด" จริง
- **4 เคส FP ที่โมเดลมั่นใจสูง** (Confidence > 0.85):
  - เคส 249 (conf=0.96), เคส 72 (conf=0.94), เคส 365 (conf=0.85), เคส 90 (conf=0.85)
- สมมติฐาน: อาจเป็น **ฟันผุระยะเริ่มต้น (Incipient Caries)** ที่ไม่ได้ถูก Annotate ใน Ground Truth
  - ความละเอียดอ่อนทางรังสี: การสลายแร่ธาตุของเคลือบฟันระยะแรกนั้นมองข้ามได้ง่าย
  - ความแปรปรวนระหว่างผู้ตรวจในการตรวจจับฟันผุมีการบันทึกไว้ชัดเจน (κ = 0.50–0.70 ในวรรณกรรม)
- **การตีความใหม่**: โมเดลในฐานะ **"ระบบคัดกรองความเห็นที่สอง (Second Opinion Screening System)"**
  - ไม่ใช่การแทนที่ทันตแพทย์ — แต่ **เสริม** ความตั้งใจทางคลินิก
  - ชี้จุดที่ควรตรวจซ้ำ โดยเฉพาะในการคัดกรองจำนวนมาก
- **ข้อผิดพลาดที่เหลือ** (FP ที่มั่นใจต่ำ + FN):
  - มักเกิดจากวัสดุอุดฟันถูกจำแนกผิดว่าเป็นฟันผุ (Radiopaque ซ้อนทับ)
  - หรือรอยโรคเล็กมากที่อยู่นอก Training Distribution ของโมเดล

### บทพูด
> "สุดท้าย มาพูดถึงข้อผิดพลาดกัน — เพราะผมคิดว่ามันเล่าเรื่องที่น่าสนใจที่สุด
>
> เรามี False Positives 293 รายการ มองแวบแรกอาจดูเยอะ แต่ให้ผมซูมเข้าไปที่กลุ่มย่อยหนึ่ง: 4 เคสที่โมเดลชี้ว่ามีฟันผุด้วย **ความมั่นใจสูงมาก** — มากกว่า 0.85 — แต่ Ground Truth บอกว่า 'ไม่มีฟันผุตรงนั้น'
>
> *[แสดงเคส 249, conf=0.96]* ดูเคสนี้ครับ โมเดลมั่นใจ 96% ว่ามีฟันผุด้านประชิดตรงนี้ แต่ผู้ Annotate ไม่ได้ทำเครื่องหมายไว้ การตีความหนึ่งคือโมเดลผิด แต่อีกการตีความหนึ่ง — ที่ผมคิดว่าน่าสนใจกว่าทางคลินิก — คือโมเดลอาจกำลังตรวจพบ **ฟันผุระยะเริ่มต้น (Incipient Caries)**: การสลายแร่ธาตุของเคลือบฟันระยะแรกที่มีความละเอียดอ่อนทางรังสีและมองข้ามได้ง่ายในการอ่านครั้งแรก
>
> นี่ไม่ใช่การคาดเดา — วรรณกรรมเกี่ยวกับ Inter-Examiner Agreement ในการตรวจจับฟันผุรายงานค่า Kappa ระหว่าง 0.50 ถึง 0.70 อย่างสม่ำเสมอ ทันตแพทย์ไม่เห็นด้วยกันเองในกรณีที่อยู่บนเส้นแบ่งตลอดเวลา
>
> ดังนั้นผมจึงอยากตีความ High-Confidence False Positives เหล่านี้ใหม่ แทนที่จะมองว่าเป็นความล้มเหลว ผมมองว่าเป็นหลักฐานว่าระบบนี้สามารถทำหน้าที่เป็น **เครื่องมือคัดกรองความเห็นที่สอง** ได้ — ไม่ใช่แทนที่การตัดสินทางคลินิก แต่เสริมมัน ชี้จุดที่ควรดูซ้ำอีกครั้ง โดยเฉพาะในสถานการณ์ที่ต้องคัดกรองจำนวนมาก เช่น การคัดกรองสาธารณสุข หรือการตรวจสอบประกัน
>
> สำหรับข้อผิดพลาดที่เหลือ — False Positives ที่มั่นใจต่ำและ False Negatives — มักเกี่ยวกับวัสดุบูรณะโลหะที่ถูกอ่านผิดว่าเป็นฟันผุ หรือรอยโรคเล็กมากที่อยู่ในขีดจำกัดของความละเอียดทางรังสี สิ่งเหล่านี้คือจุดที่ต้องปรับปรุงโมเดลต่อไป
>
> ขอบคุณครับ ยินดีรับคำถาม"

### สิ่งที่ควรแสดง
- แสดงทั้ง 4 เคส AI Eye จาก `3_The_AI_Eye_Potential/`:
  - `case_249_Proximal_conf0.96.png`
  - `case_72_Occlusal_conf0.94.png`
  - `case_365_Occlusal_conf0.85.png`
  - `case_90_Proximal_conf0.85.png`
- ซูมเข้าไปที่บริเวณที่น่าสงสัยบน X-ray; วงรอบจุดที่โมเดลชี้
- เสริม: เคส Honest Mistake จาก `4_The_Honest_Mistake/` เพื่อเปรียบเทียบ (เช่น วัสดุอุดถูกอ่านผิด)

---

## อ้างอิงด่วน — ตำแหน่งไฟล์

| รายการ | ตำแหน่ง |
|---|---|
| Hero shots | `week6/presentation_hero_shots/` |
| Perfect Match (20 ภาพ) | `presentation_hero_shots/1_The_Perfect_Match/` |
| Complex Win (328 ภาพ) | `presentation_hero_shots/2_The_Complex_Win/` |
| AI Eye (4 ภาพ) | `presentation_hero_shots/3_The_AI_Eye_Potential/` |
| Honest Mistake (20 ภาพ) | `presentation_hero_shots/4_The_Honest_Mistake/` |
| Dashboard ทั้งหมด | `week6/evaluation_output/case {N}/` |
| CSV ประเมินผล | `week6/evaluation_output/evaluation_results.csv` |
| JSON สรุป | `week6/evaluation_output/evaluation_summary.json` |
| Manifest | `presentation_hero_shots/hero_shots_manifest.json` |
